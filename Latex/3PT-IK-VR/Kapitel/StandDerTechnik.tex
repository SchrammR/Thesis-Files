\chapter{Stand der Technik / Grundlagen}

\section{Virtuelle Realität}
Boas definiert in  seiner Arbeit \cite{Boas2012} Virtuelle Realität (VR) als ein Feld der Computerwissenschaften mit dem Ziel, immersive virtuelle Welten zu erschaffen und dem Benutzer die Möglichkeit geben, mit dieser Welt zu interagieren. 
Da die Reale Welt hauptsächlich von unseren Sinnen und den Konsequenzen unseres handelns wahrgenommen wird, entsteht durch die Simulation dieser Phänomene eine Virtuelle Umgebung (VU). Dazu muss für einen oder mehrere unserer Sinne ein alternativer Stimulus präsentiert werden. Zusätzlich müssen die Bewegungen und Aktionen des Benutzers in Betracht gezogen werden und die VU muss entsprechend darauf reagieren. Ein einfaches Beispiel dafür wäre das Aufheben und Werfen eines Virtuellen Objekts.

Durch die alternatives Stimuli und die Reaktion der VU auf die Aktionen des Benutzers entstehen zwei grundsätzliche Anforderungen an das System im zusammenhang mit dem Benutzer. (Zum einen die Eingabe in die Sinne des Benutzers, zum anderen die Ausgabe des Nutzers, welche vom System erkannt werden muss.)
Holloway\cite{Holloway1995} hat in seinem Paper im Jahr 1995 eine Tabelle, die für jeden Menschlichen Sinn eine Methode der Stimulation beschreibt. Darin beschreibt er nicht nur die klasischen fünf Sinne des Menschen Hören, Schmecken, Riechen, Sehen und Tasten sondern auch kinesthetic, proprioceptic, vestibular.
Eine weitere Tabelle stellt verschiedene Geräte vor, die die Bewegungen und Aktionen des Benutzers erfassen können. Zu den Aktionen gehören Kopfbewegungen, Bewegungen des Körpers und Gliedmaßen, Fingerbewegungen, Ausrichtung der Augen, Sprache und Ausübung von Kräften.
Aktuelle Verbraucher basierte VR-Brillen fokussieren/beschränken sich in der Regel auf den Seh und Hörsinn (Audiovisuell?), da es sich herausgestellt hat, dass diese Sinne am einfachsten permanent virtualisiert werden können. (Siehe Bildschirme, Kopfhörer)\cite{Holloway1995}

Aus diesen Gründen ist der Klassische und am meisten verfügbare Weg VR zu erleben ein Head-Mounted Display (HMD), ein Gerät welches um den Kopf geschnallt wird und komplett die Augen verdeckt. HMDs haben in der Regel stereoskopische Bildschirme um 3D Welten in einer großen Blickfeld darzustellen. Jeder Bildschirme befindet sich jeweils genau vor einem Auge. Das ermöglicht die künstliche Stimulation der Visuellen Wahrnehmung. Viele HMD haben die Möglichkeit, die Distanz zwischen den Beiden Bildschirmen an die Distanz zwischen den Augen verschiedener Benutzer anzupassen. Für die wirkliche dreidimensionale Illusion werden in der Software zwei Kameras, eine für jedes Auge, eingebunden und entsprechend platziert.
Die Simulation der Auditiven Wahrnehmung kommt ebenfalls oft zum Einsatz. Da HMDs in der Regel an einen Computer angeschlossen werden müssen und diese grundsätzlich die Kapazitäten für ein Lautsprechersystem besitzen, ist es der Standard, dass VR Anwendungen mithilfe der Lautsprecher Geräusche und Musik verwenden. Alternativ ist die Verwendung von Kopfhörern möglich, da diese im Gegensatz zu Lautsprechern nur die Geräusche der VU zulassen und alle "realen" Geräusche unterdrücken.
Feedback für den Taststinn beschränkt sich bei den meisten Anwendungen auf Vibration der Controller. [Zitat, beispiel] 
Dieser krasse handschuh kann force feedback, berührung und hitze/kälte

Von den von Holloway gelisteten Aktionen die erfasst werden sollen, sind mittlerweile alle mehr oder weniger möglich zu erfassen.
Durch Gyroskope und Beschleunigungssensoren erkennt das Headset die Ausrichtung des Kopfes und kann entsprechend die Kameras in der Anwendung rotieren. Bei manchen Ausführungen wird auch die Position des Headsets und/oder anderen Trackern durch Kameras erfasst. Dadurch kann sich der Benutzer durch Bewegungen im echten Raum im virtuellen Raum bewegen. \cite{Boas2012}\cite{Holloway1995} Bei der HTC Vive beträgt die maximale Raumgröße beispielsweise 6m x 6m. ?
Aktuelle VR Kits wie die HTC Vive 2019 oder die Oculus Rift 2019 werden standardmäßig neben dem HMD mit Controllern ausgeliefert. Diese besitzen ebenfalls Tracker, mit denen ihre Position im Raum identifiziert werden kann. Der Nutzer kann mit den Controllern eine Reihe von Interaktionen Nutzen wie Aufheben und Werfen von Objekten bis zu komplexen Aufgaben wie das spannen und abfeuern eines Bogens. 
Verbraucherorientierte HMD Modelle in höheren Preisklassen (1000€+) bieten auch die Möglichkeit  zu Erfassung der Augenbewegungen. Dazu sind innerhalb des HMD Kameras angebracht, die die Rotation der Augen erfassen. Jedoch müssen Anwendungen dies auch unterstützen. [Zitat, beispiel]
Spracherkennung ist ebenfalls ein gut erforschtes Thema und es gibt bereits eine Anzahl an Spielen und Anwendungen die auf Sprachsteuerung basieren, wird aber nicht ausschließlich mit VR in Verbindung gebracht. [zizat, beispiel] 
Krasser Handschuh kann ebenfalls finger movement und force exerted messen.

Nicht nur in der Unterhaltungsbranche, sondern auch immer mehr in der Industrie.\cite{Ragan2010} *Anwendungsbeispiele*.
 


3 Seiten
\section{Immersion}
Slater\cite{Slater2003}\cite{Slater1999} definiert Immersion objektiv als das, was die Technologie hergibt. Je mehr verschiedene Sinne ein System durch virtuelle Reize stimulieren und je genauer die Erfassung der Aktionen des Benutzers und deren Übertragung in die VU ist, desto 'immersiver' ist das System. Dadurch kann laut Slater Immersion objektiv bewertet und theoretisch gemessen werden und hat nichts damit zu tun, wie verschiedene Menschen Immersion wahrnehmen. Trotzdem kann jeder das selbe Immersive System unterschiedlich Wahrnehmen und unterschiedliche Reaktionen darauf haben. Slater nennt diese Menschliche Reaktion auf Immersion 'Presence' (Präsenz, Anwesenheit) und betont in seinen Arbeiten die starke Abgrenzung von Immersion und Presence. Als Analogie verwendet er Farben. (Immersion ist Analog zur Verteilung von Wellenlängen, die alle Farben abgeben, was objektiv gemessen und beschrieben werden kann. Jeder Mensch nimmt aber Farben unterschiedlich wahr und hat verschiedene emotionale Reaktionen auf jede Farbe als andere Menschen. Also ist das Konzept der Präsenz analog zur Wahrnehmung von Farben.)
Bowman und McMahan\cite{Bowman2007} gehen bei der Definition von Slater einen Schritt weiter und fokussieren sich bei der Messung von Immersion am Grad der Visuellen Immersion, auch wenn sie nur ein Teil der gesamten Immersion eines Systems ist. Dabei hebt er die rendering Software sowie die Bildschirm Technologie vor. Seine wichtigsten Faktoren für Visuelle Immersion beinhalten beispielsweise die Auflösung und Größe eines Bildschirms, field of View sowie die Frame Rate.
Ein potentieller Vorteil eines höheren Grades an Immersion ist das Räumliche Bewusstsein. In der realen sowie der virtuellen Welt nehmen wir dauerhaft eine dreidimensionale Umgebung wahr, obwohl unsere Augen nur zweidimensionale Bilder aufnehmen. Das liegt daran, dass unser Gehirn stark darauf Optimiert ist, eine dreidimensionale Umgebung mithilfe von Stereopsis, Bewegungsparallaxe, Perspektive und Okklusion zu rekonstruieren. 
Immersive VR liefert künstliche Stimuli für all diese Tricks, die unser Gehirn verwendet. Stereopsis, also Stereoskopisches Sehen wird durch die beiden Bildschirme in den HMDs ermöglicht (+ Kameras in Software). Unter Bewegungsparallaxe können sogar in zweidimensionalen Anwendungen z.B. durch Parallax-Scrolling simliert werden. Dabei handelt es sich um den Optischen Effekt, wenn verschiedene Objekte unterschiedlich weit voneinander entfernt sind, und der Beobachter sich horizontal dazu bewegt. In dreidimensionalen virtuellen Welten ist dieser Effekt bereits gegeben. Okklusion, also der Effekt, wenn näher gelgene Objekte weiter Entfernte Objekte verdecken, sowie Perspektive sind in den meisten normalen 3D Anwendungen ebenfalls bereits gegeben und sind nicht VR spezifisch.
Das versärkte Räumliche Bewusstsein wiederum, kann zu größerer Effektivität in Anwendungen wie Wissenschaftlicher Visualisierung, Design Rewiews und Virtuellen Prototypen von 3D Objekten dienen.
Another potential benefit of immersion relates to a decrease in
information clutter. We are all familiar with computer desktops lit-
tered with overlapping icons, windows, controls, and notifications.
Some researchers are trying to address this problem with virtual
desktops, or, better yet, multiple physical monitors.
In VR, we experience an analogous problem when we add
information to our virtual worlds and visualizations—text,
numbers, glyphs, and such clutter the 3D scene. With a higher
level of immersion, however, we might be able to decrease
this clutter and increase the environment’s comprehensibility.
Specifically, increased FOV, FOR, and display resolution could
have this effect.
These and other potential benefits of immersion—such as
increased peripheral awareness or increased useful information
bandwidth—have largely gone untested until now. Demonstrating
these benefits could open the door for many other viable applications of immersive VR.

3 Seiten


\section{Self Embodiment}
Embodiment kann als Verkörperung übersetzt werden. Es beschreibt bla

Die Relevanz des Embodiments ist Analog zur Relevanz des eigenen Körpers in Alltäglichen Situationen. Unsere Körper liefern unserer Umgebung umgehend Informationen, wie unsere Aktivitäten, Aufmerksamkeit, Verfügbarkeit, Stimmung, Standort, Fähigkeiten und viele andere Faktoren. Der Körper kann indirekt durch Körpersprache Kommunizieren/beim Kommunizieren helfen oder allein Kommunizieren durch Zeichensprache.\cite{Benford2010}

Eine Konzeptualisierung des Embodiments ist, dass eine gemeinsamkeit aller Menschen ist, dass all unsere Erfahrungenen Grundlegend vom Beusstsein/der Bewusstheit eines Körpers beeinflusst ist.
lived experience = erlebnis
Conceptualizations of Embodiment One thing that all humans share is the fact that our lived experience is profoundly affected by our awareness of a body—physical or not. While theories of embodiment are relevant to many fields, it is most commonly defined as “how culture ‘gets under the skin,’ or the relationship of how sociocultural dynamics become translated into biological realities in the body,” according to anthropologist Anderson- Fye

Embodiment has also been discussed in relation to presence in virtual environments [20], [21], especially since there is evidence to suggest that a virtual body in the context of a head-mounted, display-based virtual reality is a critical contributor to the sense of being in the virtual location [22]. Kilteni et al. state that exploitation of immersive virtual reality has allowed a reframing of the question of felt embodiment to whether it is possible to experience the same sensations toward a virtual body inside an immersive virtual environment as toward the biological body and, if so, to what extent [23]. They offer a working definition that states that a sense of embodiment consists of three subcomponents: the sense of self-location, the sense of agency, and the sense of body ownership [23].


They offer a working definition that states that a sense of embodiment consists of three subcomponents: the sense of self-location, the sense of agency, and the sense of body ownership [23].
\cite{Tham2018}

Understanding and defining the SoE toward an ar-
tificial body can draw on ideas from recent proposals concerned with the embodiment ofartificial body parts (i.e., specific limbs), by extending these ideas to artificial whole bodies. According to de Vignemont (2011, p. 3), an object ‘‘E is embodied ifand only if some properties ofE are processed in the same way as the properties ofone’s body.’’ This definition is in line with that of Blanke and Metzinger (2009, p. 7) who state that em- bodiment includes the ‘‘subjective experience ofusing and ‘having’ a body.’’ Therefore, the following defini- tion is adopted:
SoE toward a body B is the sense that emerges when
B’s properties are processed as if they were the proper- ties ofone’s own biological body. (Definition: D)
\cite{Kilteni2012}

dann - alle drei:
sense of self location
sense of agency
sense of body ownership

dazu sind auch fragen in meinem bogen



3 Seiten

\section{Avatare}
ganz viel shit warum avatare geil sind was es bringt was damit gemacht wurde.
Damit die Benutzer den anderen Benutzern nicht als leere Hülle angezeigt werden, kommen Avatare zum Einsatz. Diese Helfen sich gegenseitig zu identifizieren und steigern zugleich das Embodiment des Nutzers selbst. 

Wichtig ist dabei wie die Körper dargestellt werden, sowohl beim eigenen Avatar als auch bei den von den anderen Mitbenutzern. Bei keinem Avatar kommt kein Embodiment zustande, andere können nur durch ihre Interaktion mit der Umgebung Identifiziert werden. Der Standard(Zitation) ist mittlerweile mindestens das HMD und die Controller + optional Hände zu sehen. \cite{Benford2010}
Soll ich hier alle Schritte der Avatare aufzählen?
Es gibt verschiedene Stufen, wie Avatare dargestellt werden können.
- Bei der Minimalsten Lösung wird kein Avatar dargestellt.Gar Kein Avatar, die Controller werden angezeigt, damit der Spieler sich im Raum orientieren kann.
- Nur Hände die die Controller halten. Hilft schon ein bisschen bei der Immersion. z.B. bei den Test Steam VR Anwendungen
- nur Arme. Gibts sowas? Bestimmt hilfreich bei onbody interfaces
- Kompletter Körper in Dummyform, einheitliche Textur. In dieser Arbeit verwende ich diese Variante, da ich mich auf die Auswirkungen der Avataranimationen fokussieren möchte. 
[Bild von meinem Dummy]
- Körper mit eigenen Maßen, Körpergröße passt. Z.B. wie beim MPI. 
- Komplett Texturiert, möglich auch mit echten Klamotten -> 3D Scanner

\section{Inverse Kinematics}

\section{Tracking}






