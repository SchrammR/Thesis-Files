\chapter{Stand der Technik / Grundlagen}

\section{Virtuelle Realität}
Boas definiert in  seiner Arbeit \cite{Boas2012} Virtuelle Realität (VR) als ein Feld der Computerwissenschaften mit dem Ziel, immersive virtuelle Welten zu erschaffen und dem Benutzer die Möglichkeit geben, mit dieser Welt zu interagieren. 
Da die Reale Welt hauptsächlich von unseren Sinnen und den Konsequenzen unseres handelns wahrgenommen wird, entsteht durch die Simulation dieser Phänomene eine Virtuelle Umgebung (VU). Dazu muss für einen oder mehrere unserer Sinne ein alternativer Stimulus präsentiert werden. Zusätzlich müssen die Bewegungen und Aktionen des Benutzers in Betracht gezogen werden und die VU muss entsprechend darauf reagieren. Ein einfaches Beispiel dafür wäre das Aufheben und Werfen eines Virtuellen Objekts.

Durch die alternatives Stimuli und die Reaktion der VU auf die Aktionen des Benutzers entstehen zwei grundsätzliche Anforderungen an das System im zusammenhang mit dem Benutzer. (Zum einen die Eingabe in die Sinne des Benutzers, zum anderen die Ausgabe des Nutzers, welche vom System erkannt werden muss.)
Holloway\cite{Holloway1995} hat in seinem Paper im Jahr 1995 eine Tabelle, die für jeden Menschlichen Sinn eine Methode der Stimulation beschreibt. Darin beschreibt er nicht nur die klasischen fünf Sinne des Menschen Hören, Schmecken, Riechen, Sehen und Tasten sondern auch kinesthetic, proprioceptic, vestibular.
Eine weitere Tabelle stellt verschiedene Geräte vor, die die Bewegungen und Aktionen des Benutzers erfassen können. Zu den Aktionen gehören Kopfbewegungen, Bewegungen des Körpers und Gliedmaßen, Fingerbewegungen, Ausrichtung der Augen, Sprache und Ausübung von Kräften.
Aktuelle Verbraucher basierte VR-Brillen fokussieren/beschränken sich in der Regel auf den Seh und Hörsinn (Audiovisuell?), da es sich herausgestellt hat, dass diese Sinne am einfachsten permanent virtualisiert werden können. (Siehe Bildschirme, Kopfhörer)\cite{Holloway1995}

Aus diesen Gründen ist der Klassische und am meisten verfügbare Weg VR zu erleben ein Head-Mounted Display (HMD), ein Gerät welches um den Kopf geschnallt wird und komplett die Augen verdeckt. HMDs haben in der Regel stereoskopische Bildschirme um 3D Welten in einer großen Blickfeld darzustellen. Jeder Bildschirme befindet sich jeweils genau vor einem Auge. Das ermöglicht die künstliche Stimulation der Visuellen Wahrnehmung. Viele HMD haben die Möglichkeit, die Distanz zwischen den Beiden Bildschirmen an die Distanz zwischen den Augen verschiedener Benutzer anzupassen. Für die wirkliche dreidimensionale Illusion werden in der Software zwei Kameras, eine für jedes Auge, eingebunden und entsprechend platziert.
Die Simulation der Auditiven Wahrnehmung kommt ebenfalls oft zum Einsatz. Da HMDs in der Regel an einen Computer angeschlossen werden müssen und diese grundsätzlich die Kapazitäten für ein Lautsprechersystem besitzen, ist es der Standard, dass VR Anwendungen mithilfe der Lautsprecher Geräusche und Musik verwenden. Alternativ ist die Verwendung von Kopfhörern möglich, da diese im Gegensatz zu Lautsprechern nur die Geräusche der VU zulassen und alle "realen" Geräusche unterdrücken.
Feedback für den Taststinn beschränkt sich bei den meisten Anwendungen auf Vibration der Controller. [Zitat, beispiel] 
Dieser krasse handschuh kann force feedback, berührung und hitze/kälte

Von den von Holloway gelisteten Aktionen die erfasst werden sollen, sind mittlerweile alle mehr oder weniger möglich zu erfassen.
Durch Gyroskope und Beschleunigungssensoren erkennt das Headset die Ausrichtung des Kopfes und kann entsprechend die Kameras in der Anwendung rotieren. Bei manchen Ausführungen wird auch die Position des Headsets und/oder anderen Trackern durch Kameras erfasst. Dadurch kann sich der Benutzer durch Bewegungen im echten Raum im virtuellen Raum bewegen. \cite{Boas2012}\cite{Holloway1995} Bei der HTC Vive beträgt die maximale Raumgröße beispielsweise 6m x 6m. ?
Aktuelle VR Kits wie die HTC Vive 2019 oder die Oculus Rift 2019 werden standardmäßig neben dem HMD mit Controllern ausgeliefert. Diese besitzen ebenfalls Tracker, mit denen ihre Position im Raum identifiziert werden kann. Der Nutzer kann mit den Controllern eine Reihe von Interaktionen Nutzen wie Aufheben und Werfen von Objekten bis zu komplexen Aufgaben wie das spannen und abfeuern eines Bogens. 
Verbraucherorientierte HMD Modelle in höheren Preisklassen (1000€+) bieten auch die Möglichkeit  zu Erfassung der Augenbewegungen. Dazu sind innerhalb des HMD Kameras angebracht, die die Rotation der Augen erfassen. Jedoch müssen Anwendungen dies auch unterstützen. [Zitat, beispiel]
Spracherkennung ist ebenfalls ein gut erforschtes Thema und es gibt bereits eine Anzahl an Spielen und Anwendungen die auf Sprachsteuerung basieren, wird aber nicht ausschließlich mit VR in Verbindung gebracht. [zizat, beispiel] 
Krasser Handschuh kann ebenfalls finger movement und force exerted messen.

Nicht nur in der Unterhaltungsbranche, sondern auch immer mehr in der Industrie.\cite{Ragan2010} *Anwendungsbeispiele*.
 

\section{Immersion}
Slater\cite{Slater2003}\cite{Slater1999} definiert Immersion objektiv als die Technologischen Kapazitäten eines Systems. Je mehr verschiedene Sinne ein System durch virtuelle Reize stimulieren und je genauer die Erfassung der Aktionen des Benutzers und deren Übertragung in die VU ist, desto 'immersiver' ist das System. Dadurch kann laut Slater Immersion objektiv bewertet und theoretisch gemessen werden und hat nichts damit zu tun, wie verschiedene Menschen Immersion wahrnehmen. Trotzdem kann jeder das selbe Immersive System unterschiedlich Wahrnehmen und unterschiedliche Reaktionen darauf haben. Slater nennt diese Menschliche Reaktion auf Immersion 'Presence' (Präsenz, Anwesenheit) und betont in seinen Arbeiten die starke Abgrenzung von Immersion und Presence. Als Analogie verwendet er Farben. (Immersion ist Analog zur Verteilung von Wellenlängen, die alle Farben abgeben, was objektiv gemessen und beschrieben werden kann. Jeder Mensch nimmt aber Farben unterschiedlich wahr und hat verschiedene emotionale Reaktionen auf jede Farbe als andere Menschen. Also ist das Konzept der Präsenz analog zur Wahrnehmung von Farben.). Presence beschreibt also die Beziehung zwischen einem selbst und der Umgebung.
Bowman und McMahan\cite{Bowman2007} gehen bei der Definition von Slater einen Schritt weiter und fokussieren sich bei der Messung von Immersion am Grad der Visuellen Immersion, auch wenn sie nur ein Teil der gesamten Immersion eines Systems ist. Dabei hebt er die rendering Software sowie die Bildschirmtechnologie vor. Seine wichtigsten Faktoren für Visuelle Immersion beinhalten beispielsweise die Auflösung und Größe eines Bildschirms, field of View sowie die Frame Rate.
Ein potentieller Vorteil eines höheren Grades an Immersion ist das Räumliche Bewusstsein. In der realen sowie der virtuellen Welt nehmen wir dauerhaft eine dreidimensionale Umgebung wahr, obwohl unsere Augen nur zweidimensionale Bilder aufnehmen. Das liegt daran, dass unser Gehirn stark darauf Optimiert ist, eine dreidimensionale Umgebung mithilfe von Stereopsis, Bewegungsparallaxe, Perspektive und Okklusion zu rekonstruieren. 
Immersive VR liefert künstliche Stimuli für all diese Tricks, die unser Gehirn verwendet. Stereopsis, also Stereoskopisches Sehen wird durch die beiden Bildschirme in den HMDs ermöglicht (+ Kameras in Software). Unter Bewegungsparallaxe können sogar in zweidimensionalen Anwendungen z.B. durch Parallax-Scrolling simliert werden. Dabei handelt es sich um den Optischen Effekt, wenn verschiedene Objekte unterschiedlich weit voneinander entfernt sind, und der Beobachter sich horizontal dazu bewegt. In dreidimensionalen virtuellen Welten ist dieser Effekt bereits gegeben. Okklusion, also der Effekt, wenn näher gelgene Objekte weiter Entfernte Objekte verdecken, sowie Perspektive sind in den meisten normalen 3D Anwendungen ebenfalls bereits gegeben und sind nicht VR spezifisch.
Das versärkte Räumliche Bewusstsein wiederum, kann zu größerer Effektivität in Anwendungen wie Wissenschaftlicher Visualisierung, Design Rewiews und Virtuellen Prototypen von 3D Objekten dienen.

Another potential benefit of immersion relates to a decrease in
information clutter. We are all familiar with computer desktops lit-
tered with overlapping icons, windows, controls, and notifications.
Some researchers are trying to address this problem with virtual
desktops, or, better yet, multiple physical monitors.
In VR, we experience an analogous problem when we add
information to our virtual worlds and visualizations—text,
numbers, glyphs, and such clutter the 3D scene. With a higher
level of immersion, however, we might be able to decrease
this clutter and increase the environment’s comprehensibility.
Specifically, increased FOV, FOR, and display resolution could
have this effect.
These and other potential benefits of immersion—such as
increased peripheral awareness or increased useful information
bandwidth—have largely gone untested until now. Demonstrating
these benefits could open the door for many other viable applications of immersive VR.


\section{Self Embodiment}
Embodiment kann als Verkörperung übersetzt werden. Damit ist gemeint, dass dem Benutzer ein angemessenes/passendes Selbstbild zugewiesen/bereitgestellt wird um ihn für sich selbst und, in kollaborativen Situationen, für andere zu repräsentieren. [Dafür werden Avatare eingesetzt]
Die Relevanz/Wichtigkeit des Embodiments ist Analog zur Relevanz des eigenen Körpers in Alltäglichen Situationen. Unsere Körper liefern unserer Umgebung umgehend Informationen, wie unsere Anwesenheit, Aktivitäten, Aufmerksamkeit, Verfügbarkeit, Stimmung, Standort, Fähigkeiten und viele andere Faktoren. Der Körper kann durch Gesten und Körpersprache indirekt kommunizieren. Durch Zeichensprache ist sogar eine direkte Kommunikations alternative zur Sprache möglich.\cite{Benford2010}

Eine Konzeptualisierung des Embodiments ist, dass eine Gemeinsamkeit aller Menschen ist, dass all unsere Erfahrungen Grundlegend vom Bewusstsein/der Bewusstheit eines Körpers beeinflusst ist. Unsere Erlebnisse sind Grundlegend davon beeinflusst, dass wir unseres Körpers bewusst sind, egal ob der Körper physisch vorhanden ist oder nicht \cite{Tham2018}
. Kilteni et al. \cite{Kilteni2012} geben an, dass das ausnutzen von immersivem VR die Frage aufwirft/neu formuliert, ob es möglich ist, die selben Sinneseindrücke/Empfindungen für einen virtuellen Körper in einer immersiven VU wie zu dem biologischen Körper zu fühlen und wenn ja, in welchem Ausmaß. Sie lassen sich  dabei von Forschung inspirieren, die sich mit Embodiment von künstlichen Körperteilen/Prothesen auseinandersetzt, indem diese Konzepte zu kompletten künstlichen Körpern erweitern. Zusammenfassend besagt ihre Definition von Embodiment, dass ein Objekt "Embodied" ist, also verkörpert wird, wenn manche Eigenschaften des Objekts subjektiv wie die Eigenschaften des eigenen biologischen Körpers behandelt werden und so das Gefühl,  einen Körper zu besitzen,  bei der Person auslöst.
Weiter definieren Kilteni et. al., dass das Gefühl Embodiments sich in drei Unterelemente aufteilen lässt. Erstens, das Gefühl, den eigenen Standort zu kennen(self-location).  Dies grenzt sich von der Erfahrung von 'Presence' davon ab, dass die self-location nicht die Position innerhalb eines Raums beschreibt, sondern in welchem Körper man sich befindet. Zweitens, das Gefühl der Entscheidungsfreiheit(agency). Agency verweist auf das Gefühl, motorische Kontrolle über den eigenen Körper zu haben. Das Gefühl ist beispielsweise gegeben, wenn man seinen eigenen Arm bewegen kann wann und wie man das möchte. Ein Gegenbeispiel, bei dem die Agency gestört wird, ist das unintentionale schütteln der Hände bei  Parkinson Patienten. Das Dritte Unterelement ist body ownership (das Gefühl, einen eigenen Körper zu besitzen), was die Selbstzuschreibung eines Körper beschreibt. Es hat einen besitzergreifenden Charakter und impliziert, dass der Körper die Quelle der gefühlten Empfindungen ist. Beispiel bitte

Messbarkeit - Embodiment ist nicht ja/nein sondern eine kontinuierliche Skala
vielleicht noch wie die einzelnen sachen gemessen werden können
\cite{Kilteni2012}

The type oftask completed in the SVE may also affect the performance elicited by different level ofembodiments. Competitive or cooperative tasks are likely to show a greater difference on variables such as physiological response, aggression, or perceptions ofthe avatar. \cite{pan2017}

Embodiment in Social Media
\cite{Schwartz2018}

überleitung zu Avatare



\section{Avatare}
Avatare sind Digitale Repräsentationen von uns selbst. Ihre Darstellung variiert stark abhängig vom Kontext in dem sie eingesetzt werden. Sie reichen von einfachen Zeichnungen oder Bildern, die den Benutzer darstellen, wie es in manchmal in Social Media zu Kommunikation eingesetzt wird, bis zu detailreichen, komplett ausgearbeiteten 3D Modellen, welche perfekt auf die jeweilige Person zugeschnitten sind welche in High-End Simulationen zu finden sind.
Eine wichtige Eigenschaft für Avatare neben der Darstellung ist die Kontrolle, die der Nutzer über den Avatar hat. Die Kontrolle reicht wie die Darstellung von komplett passiv und uninteraktiv wie bei Bildern bis zu dynamischen und komplett kontrollierbaren Avataren wie es oft in Computerspielen zu sehen ist.
Je höher die Kontrolle über den Avatar ist, desto höher ist die Immersion und somit auch das mögliche Embodiment, welches der Nutzer erleben kann. Vorallem die Kategorie der Agency von Embodiment ist davon betroffen, da eine Aktion des Nutzers bei hoher kontrollierbarkeit durch direkte Verknüpfung mit dem Avatar eine Aktion des Avatars auslöst.\cite{Biocca2014}

Liste warum Avatare geil sind?



Obwohl Avatare eine höhere Immersion bieten, setzen relativ wenige HMD-basierte VR-Systeme Avatare ein, die den kompletten Körper repräsentieren.\cite{Pan2017} cons?



Damit die Benutzer den anderen Benutzern nicht als leere Hülle angezeigt werden, kommen Avatare zum Einsatz. Diese Helfen sich gegenseitig zu identifizieren und steigern zugleich das Embodiment des Nutzers selbst. 

Wichtig ist dabei wie die Körper dargestellt werden, sowohl beim eigenen Avatar als auch bei den von den anderen Mitbenutzern. Bei keinem Avatar kommt kein Embodiment zustande, andere können nur durch ihre Interaktion mit der Umgebung Identifiziert werden. Der Standard(Zitation) ist mittlerweile mindestens das HMD und die Controller + optional Hände zu sehen. \cite{Benford2010}
Soll ich hier alle Schritte der Avatare aufzählen?
Es gibt verschiedene Stufen, wie Avatare dargestellt werden können.
- Bei der Minimalsten Lösung wird kein Avatar dargestellt.Gar Kein Avatar, die Controller werden angezeigt, damit der Spieler sich im Raum orientieren kann.
- Nur Hände die die Controller halten. Hilft schon ein bisschen bei der Immersion. z.B. bei den Test Steam VR Anwendungen
- nur Arme. Gibts sowas? Bestimmt hilfreich bei onbody interfaces
- Kompletter Körper in Dummyform, einheitliche Textur. In dieser Arbeit verwende ich diese Variante, da ich mich auf die Auswirkungen der Avataranimationen fokussieren möchte. 
[Bild von meinem Dummy]
- Körper mit eigenen Maßen, Körpergröße passt. Z.B. wie beim MPI. 
- Komplett Texturiert, möglich auch mit echten Klamotten -> 3D Scanner

\section{Inverse Kinematics}

\section{Tracking}






